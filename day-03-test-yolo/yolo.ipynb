{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a29156",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Tuple\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "YOLOv1 (You Only Look Once) implementation from scratch in PyTorch\n",
    "=================================================================\n",
    "This script defines:\n",
    "    • CNN backbone + detection head exactly as described in the 2016 paper.\n",
    "    • Custom loss function that combines localization, confidence, and class\n",
    "      prediction losses.\n",
    "    • Minimal training loop skeleton that you can adapt to your own dataset.\n",
    "\n",
    "Author  : ChatGPT (OpenAI o3)\n",
    "Created : 2025‑06‑30\n",
    "License : MIT\n",
    "\n",
    "Usage\n",
    "-----\n",
    "$ python yolov1_scratch.py  # runs a dummy forward & loss check on random data\n",
    "\n",
    "To train on a real dataset:\n",
    "    1. Prepare an annotation file in PASCAL‑VOC format or convert it\n",
    "       to YOLO‑style (``S=7, B=2``).\n",
    "    2. Implement a ``YOLODataset`` that returns: img_tensor, target_tensor where\n",
    "       ``target_tensor`` has shape ``(S, S, 30)``. (See ``dummy_targets`` below.)\n",
    "    3. Replace the ``RandomDataset`` with your dataset in the DataLoader.\n",
    "    4. Adjust hyper‑parameters in ``train()`` as needed.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "• This code is educational – it aims at clarity over raw speed.\n",
    "• No funky helper libraries: only PyTorch + torchvision (for transforms).\n",
    "• Tested with PyTorch 2.3.0 and Python 3.10.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Building Blocks\n",
    "# ---------------------------\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    \"\"\"(Conv → BatchNorm → LeakyReLU) block used throughout the Darknet backbone.\"\"\"\n",
    "\n",
    "    def __init__(self, in_c: int, out_c: int, **conv_kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_c, out_c, bias=False, **conv_kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_c)\n",
    "        self.act = nn.LeakyReLU(0.1, inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # noqa: D401\n",
    "        return self.act(self.batchnorm(self.conv(x)))\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. YOLOv1 Backbone + Head\n",
    "# ---------------------------\n",
    "\n",
    "S = 7   # grid size\n",
    "B = 2   # bounding boxes / grid cell\n",
    "C = 20  # number of classes (VOC‑20)\n",
    "\n",
    "# Darknet‑style architecture configuration.\n",
    "# Tuples : (kernel_size, filters, stride, padding)\n",
    "# \"M\"    : MaxPool 2×2 stride 2\n",
    "ARCH_CONFIG: List[Tuple | str] = [\n",
    "    (7, 64, 2, 3),\n",
    "    \"M\",\n",
    "    (3, 192, 1, 1),\n",
    "    \"M\",\n",
    "    (1, 128, 1, 0),\n",
    "    (3, 256, 1, 1),\n",
    "    (1, 256, 1, 0),\n",
    "    (3, 512, 1, 1),\n",
    "    \"M\",\n",
    "    *[(1, 256, 1, 0), (3, 512, 1, 1)] * 4,\n",
    "    (3, 1024, 1, 1),\n",
    "    \"M\",\n",
    "    *[(1, 512, 1, 0), (3, 1024, 1, 1)] * 2,\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 2, 1),\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 1, 1),\n",
    "]\n",
    "\n",
    "\n",
    "class YOLOv1(nn.Module):\n",
    "    \"\"\"Complete YOLOv1 end‑to‑end model.\"\"\"\n",
    "\n",
    "    def __init__(self, split_size: int = S, num_boxes: int = B, num_classes: int = C):\n",
    "        super().__init__()\n",
    "        self.S, self.B, self.C = split_size, num_boxes, num_classes\n",
    "\n",
    "        self.backbone = self._create_conv_layers(ARCH_CONFIG)\n",
    "\n",
    "        # Fully‑connected detection head (flatten → FC4096 → FC(output))\n",
    "        # Final output dim = S×S×(B×5 + C)\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * self.S * self.S, 4096),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(4096, self.S * self.S * (self.C + self.B * 5)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # noqa: D401\n",
    "        x = self.backbone(x)\n",
    "        x = self.fcs(x)\n",
    "        return x.view(-1, self.S, self.S, self.C + self.B * 5)\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_conv_layers(config: List[Tuple | str]) -> nn.Sequential:  # noqa: D401\n",
    "        layers: List[nn.Module] = []\n",
    "        in_channels = 3\n",
    "        for layer in config:\n",
    "            if isinstance(layer, tuple):\n",
    "                k, filters, stride, pad = layer\n",
    "                layers.append(\n",
    "                    CNNBlock(\n",
    "                        in_c=in_channels,\n",
    "                        out_c=filters,\n",
    "                        kernel_size=k,\n",
    "                        stride=stride,\n",
    "                        padding=pad,\n",
    "                    )\n",
    "                )\n",
    "                in_channels = filters\n",
    "            elif layer == \"M\":\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected layer type: {layer}\")\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Loss function\n",
    "# ---------------------------\n",
    "\n",
    "class YOLOLoss(nn.Module):\n",
    "    \"\"\"Standard YOLOv1 loss with λ_coord = 5, λ_noobj = 0.5.\"\"\"\n",
    "\n",
    "    def __init__(self, S: int = S, B: int = B, C: int = C, lambda_coord: float = 5.0, lambda_noobj: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "        self.S, self.B, self.C = S, B, C\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:  # noqa: D401\n",
    "        # preds / targets shape : (N, S, S, 30)\n",
    "        N = preds.shape[0]\n",
    "\n",
    "        # Split predictions\n",
    "        pred_boxes = preds[..., : self.B * 5].view(N, self.S, self.S, self.B, 5)\n",
    "        pred_classes = preds[..., self.B * 5 :]\n",
    "\n",
    "        # Split targets\n",
    "        target_boxes = targets[..., : self.B * 5].view(N, self.S, self.S, self.B, 5)\n",
    "        target_classes = targets[..., self.B * 5 :]\n",
    "\n",
    "        # Identity mask: where object exists in target (assume first bbox has obj conf)\n",
    "        obj_mask = targets[..., 4].unsqueeze(-1)  # shape (N, S, S, 1)\n",
    "\n",
    "        # Localization (x,y,w,h) – only where objects exist, only responsible bbox (idx0)\n",
    "        # YOLOv1 picks first bbox as responsible if we’re using simplified targets\n",
    "        pred_xywh = pred_boxes[..., 0:4]\n",
    "        target_xywh = target_boxes[..., 0:4]\n",
    "\n",
    "        coord_loss = self.mse(obj_mask * pred_xywh, obj_mask * target_xywh)\n",
    "\n",
    "        # Confidence loss (object + no‑object)\n",
    "        pred_conf = pred_boxes[..., 4]\n",
    "        target_conf = target_boxes[..., 4]\n",
    "\n",
    "        conf_obj = self.mse(obj_mask.squeeze(-1) * pred_conf, obj_mask.squeeze(-1) * target_conf)\n",
    "        conf_noobj = self.mse((1 - obj_mask.squeeze(-1)) * pred_conf, (1 - obj_mask.squeeze(-1)) * target_conf)\n",
    "\n",
    "        # Classification loss (only where object exists)\n",
    "        class_loss = self.mse(obj_mask * pred_classes, obj_mask * target_classes)\n",
    "\n",
    "        total = (\n",
    "            self.lambda_coord * coord_loss\n",
    "            + conf_obj\n",
    "            + self.lambda_noobj * conf_noobj\n",
    "            + class_loss\n",
    "        ) / N  # normalize by batch\n",
    "        return total\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Dummy Dataset (replace with your own)\n",
    "# ---------------------------\n",
    "\n",
    "class RandomDataset(Dataset):\n",
    "    \"\"\"Returns random images & dummy targets – just for sanity check.\"\"\"\n",
    "\n",
    "    def __init__(self, size: int = 256):\n",
    "        self.size = size\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((448, 448)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:  # noqa: D401\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx: int):  # noqa: D401\n",
    "        img = torch.rand(3, 448, 448)  # Random RGB image\n",
    "        target = torch.zeros(S, S, C + B * 5)\n",
    "        # Put a dummy object in cell (3,4)\n",
    "        target[3, 4, 0:5] = torch.tensor([0.5, 0.5, 0.2, 0.3, 1.0])  # bbox1\n",
    "        target[3, 4, B * 5 + 7] = 1.0  # set class‑7 (e.g., car) to 1\n",
    "        return img, target\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Training loop skeleton\n",
    "# ---------------------------\n",
    "\n",
    "def train():  # noqa: D401\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = YOLOv1().to(device)\n",
    "    criterion = YOLOLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    loader = DataLoader(RandomDataset(64), batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(3):  # quick sanity run\n",
    "        running_loss = 0.0\n",
    "        for imgs, targets in loader:\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1} | Loss: {running_loss/len(loader):.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run a tiny sanity check to ensure forward/loss compile.\n",
    "    train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
