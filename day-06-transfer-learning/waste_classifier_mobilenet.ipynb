{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ae2122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Smart Recycling Bin - Trash Classification with MobileNetV2\n",
    "# ============================================================\n",
    "\n",
    "# 1️⃣ Import Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "# Install matplotlib if not already installed\n",
    "# %pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Ganti path dataset sesuai lokasi kamu\n",
    "# Folder struktur:\n",
    "# dataset/\n",
    "#   ├── cardboard/\n",
    "#   ├── glass/\n",
    "#   ├── metal/\n",
    "#   ├── paper/\n",
    "#   ├── plastic/\n",
    "#   └── trash/\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "DATA_DIR = \"dataset\"\n",
    "IMG_SIZE = 160\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gunakan MobileNetV2 pretrained ImageNet\n",
    "base_model = mobilenet_v2.MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False  # Freeze backbone\n",
    "\n",
    "# Bangun model\n",
    "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = mobilenet_v2.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94549b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_head = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# TODO: Plot hasil training\n",
    "plt.plot(history_head.history['accuracy'], label='train_acc')\n",
    "plt.plot(history_head.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.title(\"Training Head Only\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "fine_tune_at = 100\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_ft = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# TODO: Plot hasil fine-tuning\n",
    "plt.plot(history_ft.history['accuracy'], label='train_acc')\n",
    "plt.plot(history_ft.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.title(\"Fine-Tuning\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"waste_classifier_v1.keras\")\n",
    "print(\"✅ Model saved to waste_classifier_v1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "# TODO: ganti dengan path gambar uji kamu\n",
    "test_img_path = \"sample_test/plastic_bottle.jpg\"\n",
    "\n",
    "img = load_img(test_img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "img_array = img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = mobilenet_v2.preprocess_input(img_array)\n",
    "\n",
    "pred = model.predict(img_array)\n",
    "pred_class = class_names[np.argmax(pred)]\n",
    "confidence = np.max(pred)\n",
    "\n",
    "print(f\"Predicted Class: {pred_class}\")\n",
    "print(f\"Confidence: {confidence:.2f}\")\n",
    "\n",
    "plt.imshow(load_img(test_img_path))\n",
    "plt.title(f\"Predicted: {pred_class} ({confidence:.2f})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8855e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluasi pada validation/test set\n",
    "loss, acc = model.evaluate(val_ds)\n",
    "print(f\"Validation accuracy: {acc:.4f}\")\n",
    "\n",
    "# TODO: Buat confusion matrix (opsional)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_true = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "y_pred = np.argmax(model.predict(val_ds), axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
